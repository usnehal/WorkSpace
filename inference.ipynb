{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#Import all the required libraries\n",
    "import  time\n",
    "import  pandas as pd\n",
    "import  numpy as np\n",
    "from    skimage import io\n",
    "import  random\n",
    "from    collections import Counter\n",
    "from    tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import  tensorflow as tf\n",
    "from    tensorflow import keras\n",
    "from    tensorflow.keras import layers,Model\n",
    "from    tqdm import tqdm\n",
    "from    nltk.translate.bleu_score import sentence_bleu\n",
    "import  socket\n",
    "import  pickle5 as pickle\n",
    "from    tensorflow.keras.activations import tanh\n",
    "from    tensorflow.keras.activations import softmax\n",
    "import  matplotlib.pyplot as plt\n",
    "import  time\n",
    "import  argparse\n",
    "from    sklearn.metrics import accuracy_score\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from Helper import Config, ImagesInfo, Logger, Client, TimeKeeper\n",
    "from Helper import read_image\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-s', '--server', action='store', type=str, required=False)\n",
    "parser.add_argument('-t', '--test_number', action='store', type=int, required=False)\n",
    "parser.add_argument('-v', '--verbose', action='store', type=int, required=False)\n",
    "args, unknown = parser.parse_known_args()\n",
    "print(args.server)\n",
    "\n",
    "server_ip = args.server\n",
    "test_number = args.test_number\n",
    "verbose = args.verbose\n",
    "\n",
    "if(verbose == None):\n",
    "    verbose = 1\n",
    "\n",
    "if(test_number == None):\n",
    "    test_number = 3\n",
    "\n",
    "test_scenarios = {1:\"Complete jpg file buffer transfer\", \n",
    "                    2:\"Decoded image buffer transfer\",\n",
    "                    3:\"Decoded image buffer transfer with zlib compression\"}\n",
    "\n",
    "print(\"Test scenario = %d %s\" % (test_number, test_scenarios[test_number]))\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n",
      "Test scenario = 3 Decoded image buffer transfer with zlib compression\n",
      "2021_07_13-15_24\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "total_test_images = 100\n",
    "batch_size = 32\n",
    "PREDICTIONS_THRESHOLD = 0.4"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "Logger.set_log_level(verbose)\n",
    "tk = TimeKeeper()\n",
    "cfg = Config(server_ip)\n",
    "client = Client(cfg)\n",
    "imagesInfo = ImagesInfo(cfg)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In WSL\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "new_head_model = tf.keras.models.load_model(cfg.temp_path + '/new_head_model')\n",
    "new_tail_model = tf.keras.models.load_model(cfg.temp_path + '/new_tail_model')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def process_predictions(ground_truth, prediction_tensor):\n",
    "    n = tf.squeeze(prediction_tensor).numpy()\n",
    "    df = pd.DataFrame(columns=['id_index','probability'])\n",
    "    predictions_str = ''\n",
    "    top_predictions = []\n",
    "    index = 0\n",
    "    for x in n:\n",
    "        if x > PREDICTIONS_THRESHOLD:\n",
    "            top_predictions.append(index)\n",
    "            predictions_str += \"%s(%.2f) \" % (imagesInfo.classes[index],x)\n",
    "            df = df.append({'id_index':int(index), 'probability':x},ignore_index = True)\n",
    "        index += 1\n",
    "\n",
    "    df = df.sort_values('probability', ascending=False)\n",
    "    sorted_predictions = df['id_index'].tolist()\n",
    "    sorted_predictions = [int(x) for x in sorted_predictions]\n",
    "\n",
    "    ground_truth_length = len(ground_truth)\n",
    "    predictions_length = len(sorted_predictions)\n",
    "\n",
    "    aligned_predictions = [-1] * ground_truth_length\n",
    "    TP = 0\n",
    "    for i in range(ground_truth_length):\n",
    "        if(ground_truth[i] in sorted_predictions):\n",
    "            aligned_predictions[i] = ground_truth[i]\n",
    "            TP += 1\n",
    "    accuracy = accuracy_score(ground_truth, aligned_predictions)\n",
    "\n",
    "    top_1_accuracy = 0.0\n",
    "    top_5_accuracy = 0.0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    if(predictions_length > 0):\n",
    "        if(sorted_predictions[0] in ground_truth):\n",
    "            top_1_accuracy = 1.0\n",
    "        for i in range(5):\n",
    "            if((i < predictions_length) and (sorted_predictions[i] in ground_truth)):\n",
    "                top_5_accuracy = 1.0\n",
    "\n",
    "        precision = TP / predictions_length\n",
    "    recall = TP / ground_truth_length\n",
    "    return accuracy, top_1_accuracy,top_5_accuracy,precision,recall, top_predictions, predictions_str\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def evaluate_classification(image):\n",
    "    temp_input = tf.expand_dims(read_image(image), 0) \n",
    "    h = new_head_model(temp_input)\n",
    "    s = new_tail_model(h)\n",
    "    return s\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "total_time = 0.0\n",
    "max_test_images = total_test_images\n",
    "df = pd.DataFrame(columns=['img_path','ground_truth', 'top_predict', 'Prediction', 'accuracy', 'top_1_accuracy', 'top_5_accuracy', 'precision', 'recall', 'time'])\n",
    "\n",
    "for i in tqdm(range(max_test_images)):\n",
    "    Logger.debug_print(\"\")\n",
    "    img_path = imagesInfo.all_img_vector[i]\n",
    "    # plt.imshow(image)\n",
    "    ground_truth = imagesInfo.get_segmentation_id_indexes(img_path)\n",
    "\n",
    "    test_image = img_path\n",
    "\n",
    "    t0= time.perf_counter()\n",
    "    s = evaluate_classification(test_image)\n",
    "    t1 = time.perf_counter() - t0\n",
    "    total_time = total_time + t1\n",
    "\n",
    "    accuracy, top_1_accuracy,top_5_accuracy,precision,recall, top_predictions, predictions_str = process_predictions(ground_truth,s)\n",
    "    df = df.append(\n",
    "        {'image':img_path, \n",
    "        'ground_truth':(str(imagesInfo.get_segmentation_texts(ground_truth))),\n",
    "        'top_predict':str(top_predictions),\n",
    "        'Prediction':predictions_str,\n",
    "        'accuracy':accuracy,\n",
    "        'top_1_accuracy':top_1_accuracy,\n",
    "        'top_5_accuracy':top_5_accuracy,\n",
    "        'precision':precision,\n",
    "        'recall':recall,\n",
    "        'time':t1,\n",
    "        },\n",
    "        ignore_index = True)\n",
    "    truth_str = ' '.join([str(elem) for elem in imagesInfo.get_segmentation_texts(ground_truth)])\n",
    "    Logger.debug_print(\"ground_truth  : %s\" % (truth_str))\n",
    "    Logger.debug_print(\"Prediction    : %s\" % (predictions_str))\n",
    "\n",
    "df.to_csv(cfg.temp_path + '/results_'+cfg.timestr+'.csv')\n",
    "av_column = df.mean(axis=0)\n",
    "\n",
    "Logger.milestone_print(\"accuracy        : %.2f\" % (av_column.accuracy))\n",
    "Logger.milestone_print(\"top_1_accuracy  : %.2f\" % (av_column.top_1_accuracy))\n",
    "Logger.milestone_print(\"top_5_accuracy  : %.2f\" % (av_column.top_5_accuracy))\n",
    "Logger.milestone_print(\"precision       : %.2f\" % (av_column.precision))\n",
    "Logger.milestone_print(\"recall          : %.2f\" % (av_column.recall))\n",
    "Logger.milestone_print(\"time            : %.2f\" % (av_column.time))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 100/100 [00:47<00:00,  2.12it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[92maccuracy        : 0.53\u001b[0m\n",
      "\u001b[92mtop_1_accuracy  : 0.70\u001b[0m\n",
      "\u001b[92mtop_5_accuracy  : 0.90\u001b[0m\n",
      "\u001b[92mprecision       : 0.68\u001b[0m\n",
      "\u001b[92mrecall          : 0.53\u001b[0m\n",
      "\u001b[92mtime            : 0.45\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}