{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#!pip install --upgrade git+https://github.com/EmGarr/kerod.git"
   ],
   "outputs": [],
   "metadata": {
    "id": "1jVKNjhdLFUQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print('GPU device not found')\n",
    "else:\n",
    "    print('Found GPU at: {}'.format(device_name))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU device not found\n"
     ]
    }
   ],
   "metadata": {
    "id": "CET-72i5EmKn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import  functools\n",
    "import  tensorflow as tf\n",
    "import  tensorflow_datasets as tfds\n",
    "from    tensorflow.keras.utils import to_categorical\n",
    "import  matplotlib.pyplot as plt\n",
    "from    tensorflow.keras import layers\n",
    "from    tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data_dir='/home/suphale/coco'\n",
    "N_LABELS = 80\n",
    "N_EPOCHS = 1\n",
    "TRAIN_MODE = False\n",
    "split_train = \"train[:1%]\"\n",
    "split_val = \"validation[:1%]\"\n",
    "h_image_height = 299\n",
    "h_image_width = 299\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class BoxField:\n",
    "    BOXES = 'bbox'\n",
    "    KEYPOINTS = 'keypoints'\n",
    "    LABELS = 'label'\n",
    "    MASKS = 'masks'\n",
    "    NUM_BOXES = 'num_boxes'\n",
    "    SCORES = 'scores'\n",
    "    WEIGHTS = 'weights'\n",
    "\n",
    "class DatasetField:\n",
    "    IMAGES = 'images'\n",
    "    IMAGES_INFO = 'images_information'\n",
    "    IMAGES_PMASK = 'images_padding_mask'\n",
    "\n",
    "def my_preprocess(inputs):\n",
    "    image = inputs['image']\n",
    "    image = tf.image.resize(image, (h_image_height, h_image_width))\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 127.5\n",
    "    image -= 1.\n",
    "\n",
    "    targets = inputs['objects']\n",
    "\n",
    "    image_information = tf.cast(tf.shape(image)[:2], dtype=tf.float32)\n",
    "\n",
    "    inputs = {DatasetField.IMAGES: image, DatasetField.IMAGES_INFO: image_information}\n",
    "\n",
    "    # ground_truths = {\n",
    "    #     BoxField.BOXES: targets[BoxField.BOXES] * tf.tile(image_information[tf.newaxis], [1, 2]),\n",
    "    #     BoxField.LABELS: tf.cast(targets[BoxField.LABELS], tf.int32),\n",
    "    #     BoxField.NUM_BOXES: tf.shape(targets[BoxField.LABELS]),\n",
    "    #     BoxField.WEIGHTS: tf.fill(tf.shape(targets[BoxField.LABELS]), 1.0)\n",
    "    # }\n",
    "    ground_truths = tf.cast(targets[BoxField.LABELS], tf.int32)\n",
    "    ground_truths = tf.one_hot(ground_truths, depth=N_LABELS, dtype=tf.int32)\n",
    "    ground_truths = tf.reduce_sum(ground_truths, 0)\n",
    "    ground_truths = tf.greater( ground_truths, tf.constant( 0 ) )    \n",
    "    ground_truths = tf.where (ground_truths, 1, 0) \n",
    "    return image, ground_truths\n",
    "\n",
    "def expand_dims_for_single_batch(image, ground_truths):\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    ground_truths = tf.expand_dims(ground_truths, axis=0)\n",
    "    return image, ground_truths\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "ds_train, ds_info = tfds.load(name=\"coco/2017\", split=split_train, data_dir=data_dir, shuffle_files=True, download=False, with_info=True)\n",
    "ds_train = ds_train.map(functools.partial(my_preprocess), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.map(expand_dims_for_single_batch, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_val = tfds.load(name=\"coco/2017\", split=split_val, data_dir=data_dir, shuffle_files=True, download=False)\n",
    "ds_val = ds_val.map(functools.partial(my_preprocess), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_val = ds_val.map(expand_dims_for_single_batch, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_val = ds_val.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function my_preprocess at 0x7f8e0674a320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function my_preprocess at 0x7f8e0674a320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: AutoGraph could not transform <function my_preprocess at 0x7f8e0674a320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "metadata": {
    "id": "1cC2k8osNGFw",
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load and train the network\n"
   ],
   "metadata": {
    "id": "9tt34CM6P-gr"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Find total number of classes in the coco dataset\n",
    "classes = ds_info.features['objects']['label'].names\n",
    "num_classes = len(classes)\n",
    "print(num_classes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "80\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "image_model = tf.keras.applications.InceptionV3(include_top=False,weights='imagenet')\n",
    "\n",
    "x = image_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "predictions = tf.keras.layers.Dense(80, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=image_model.input, outputs=predictions)\n",
    "\n",
    "for layer in image_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# model.compile(optimizer='rmsprop', loss=ncce, metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# for layer in model.layers:\n",
    "#     print(layer.trainable)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "if (TRAIN_MODE == True):\n",
    "    callbacks = [\n",
    "        TensorBoard(),\n",
    "        ModelCheckpoint('checkpoints/')\n",
    "    ]\n",
    "\n",
    "    model.fit(ds_train, validation_data=ds_val, epochs=N_EPOCHS, callbacks=callbacks)\n",
    "    # Save the weights for the serving\n",
    "    model.save_weights('/home/suphale/WorkSpace/temp_model/coco_classification_weights.h5')\n",
    "else:\n",
    "    model.load_weights('/home/suphale/WorkSpace/saved_model/coco_classification_weights.h5')    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualisation of few images"
   ],
   "metadata": {
    "id": "_ZrcN9snlNxh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "for test_index in range(10):\n",
    "    sample_img_batch, sample_cap_batch = next(iter(ds_val))\n",
    "    s = model(sample_img_batch)\n",
    "    # plt.imshow(tf.squeeze(sample_img_batch, [0]))\n",
    "\n",
    "    print(\"Reference:\")\n",
    "    n = sample_cap_batch.numpy()\n",
    "    index = 0\n",
    "    for x in n[0]:\n",
    "        if x > 0.1:\n",
    "            print(\"%s,\" % (classes[index]), end=' ')\n",
    "        index += 1\n",
    "    print(\"\")\n",
    "    print(\"Prediction:\")\n",
    "    n = s.numpy()\n",
    "    index = 0\n",
    "    for x in n[0]:\n",
    "        if x > 0.5:\n",
    "            print(\"%s(%.2f),\" % (classes[index],x), end=' ')\n",
    "        index += 1\n",
    "    print(\"\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reference:\n",
      "person, tennis racket, \n",
      "Prediction:\n",
      "person(0.99), sports ball(0.52), tennis racket(1.00), \n",
      "Reference:\n",
      "remote, book, \n",
      "Prediction:\n",
      "bottle(0.54), \n",
      "Reference:\n",
      "person, car, handbag, \n",
      "Prediction:\n",
      "person(0.96), skateboard(0.89), \n",
      "Reference:\n",
      "person, car, handbag, \n",
      "Prediction:\n",
      "person(0.96), skateboard(0.89), \n",
      "Reference:\n",
      "person, tennis racket, \n",
      "Prediction:\n",
      "person(0.99), sports ball(0.52), tennis racket(1.00), \n",
      "Reference:\n",
      "remote, book, \n",
      "Prediction:\n",
      "bottle(0.54), \n",
      "Reference:\n",
      "person, tennis racket, \n",
      "Prediction:\n",
      "person(0.99), sports ball(0.52), tennis racket(1.00), \n",
      "Reference:\n",
      "remote, book, \n",
      "Prediction:\n",
      "bottle(0.54), \n",
      "Reference:\n",
      "person, tennis racket, \n",
      "Prediction:\n",
      "person(0.99), sports ball(0.52), tennis racket(1.00), \n",
      "Reference:\n",
      "remote, book, \n",
      "Prediction:\n",
      "bottle(0.54), \n"
     ]
    }
   ],
   "metadata": {
    "id": "LXhTDloWlNxi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensorboard"
   ],
   "metadata": {
    "id": "CD14aaUMEudZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "TensorBoard = False\n",
    "if(TensorBoard == True):\n",
    "    # Load TENSORBOARD\n",
    "    %load_ext tensorboard\n",
    "    # Start TENSORBOARD\n",
    "    %tensorboard --logdir logs"
   ],
   "outputs": [],
   "metadata": {
    "id": "Ec4-mdjcR_wy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from tensorflow import keras  # or import keras for standalone version\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "org_model = tf.keras.models.load_model('model')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "model_config = org_model.get_config()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "max_layer_index = len(model_config['layers']) - 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "split_layer = 4\n",
    "\n",
    "new_head_model_config = {}\n",
    "new_head_model_config['name'] = 'head_model'\n",
    "new_head_model_config['layers'] = []\n",
    "new_head_model_config['input_layers'] = [[model_config['layers'][0]['name'],0,0]]\n",
    "new_head_model_config['output_layers'] = [[model_config['layers'][split_layer-1]['name'],0,0]]\n",
    "\n",
    "for index in range(split_layer):\n",
    "    print(\"%d %s\" % (index, model_config['layers'][index]['name']) )\n",
    "    new_head_model_config['layers'].append(model_config['layers'][index])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 input_1\n",
      "1 conv2d\n",
      "2 batch_normalization\n",
      "3 activation\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import copy\n",
    "\n",
    "new_tail_model_config = copy.deepcopy(model_config)\n",
    "new_tail_model_config['name'] = 'tail_model'\n",
    "new_tail_model_config['input_layers'] = [[model_config['layers'][split_layer]['name'],0,0]]\n",
    "new_tail_model_config['output_layers'] = [[model_config['layers'][max_layer_index]['name'],0,0]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# tuple(org_model.layers[0].output.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "new_input_layer = {\n",
    "                      'name': 'new_input',\n",
    "                      'class_name': 'InputLayer',\n",
    "                      'config': {\n",
    "                          'batch_input_shape': tuple(org_model.layers[split_layer].output.shape),\n",
    "                          'dtype': 'float32',\n",
    "                          'sparse': False,\n",
    "                          'name': 'new_input'\n",
    "                      },\n",
    "                      'inbound_nodes': []\n",
    "                  }\n",
    "new_tail_model_config['layers'][0] = new_input_layer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "for index in range(1,split_layer):\n",
    "    print(\"%d %s\" % (index, new_tail_model_config['layers'][1]['name']) )\n",
    "    # new_tail_model_config['layers'].append(model_config['layers'][index])\n",
    "    new_tail_model_config['layers'].pop(1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 conv2d\n",
      "2 batch_normalization\n",
      "3 activation\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# input_layer_name = model_config['layers'][0]['name']\n",
    "new_tail_model_config['layers'][1]['inbound_nodes'] = [[['new_input', 0, 0, {}]]]\n",
    "new_tail_model_config['input_layers'] = [['new_input', 0, 0]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import pprint\n",
    "with open('model_config.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    # fh.write(str(model_config))\n",
    "    pp = pprint.PrettyPrinter(indent=4, stream=fh)\n",
    "    pp.pprint(str(model_config))\n",
    "with open('new_head_model_config.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    # fh.write(str(new_head_model_config))\n",
    "    pp = pprint.PrettyPrinter(indent=4, stream=fh)\n",
    "    pp.pprint(str(new_head_model_config))\n",
    "with open('new_tail_model_config.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    # fh.write(str(new_head_model_config))\n",
    "    pp = pprint.PrettyPrinter(indent=4, stream=fh)\n",
    "    pp.pprint(str(new_tail_model_config))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "new_head_model = org_model.__class__.from_config(new_head_model_config, custom_objects={})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "new_tail_model = org_model.__class__.from_config(new_tail_model_config, custom_objects={})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "with open('org_model.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    org_model.summary(print_fn=lambda x: fh.write(x + '\\n'), line_length=150)\n",
    "\n",
    "with open('new_head_model.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    new_head_model.summary(print_fn=lambda x: fh.write(x + '\\n'), line_length=150)\n",
    "\n",
    "with open('new_tail_model.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    new_tail_model.summary(print_fn=lambda x: fh.write(x + '\\n'), line_length=150)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "for index, layer in enumerate(org_model.layers[:split_layer]):\n",
    "    # print(\"[%d] %s %s\" % (index, layer.name, str(np.shape(weight))))\n",
    "    weight = layer.get_weights()\n",
    "    new_head_model_layer = new_head_model.layers[index]\n",
    "    new_head_model_layer.set_weights(weight)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "for index, layer in enumerate(org_model.layers[split_layer:max_layer_index+1]):\n",
    "    weight = layer.get_weights()\n",
    "    # print(\"[%d] %s %s\" % (index, layer.name, str(np.shape(weight))))\n",
    "    new_tail_model_layer = new_tail_model.layers[index+1]\n",
    "    # print(\"[%d] %s %s\" % (index, new_tail_model_layer.name, str(np.shape(weight))))\n",
    "    new_tail_model_layer.set_weights(weight)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "hidden_layer = new_head_model(sample_img_batch)\n",
    "print(tf.shape(hidden_layer))\n",
    "\n",
    "# new_head_model.summary(line_length=150)\n",
    "predictions = new_tail_model(hidden_layer)\n",
    "# # head_model.summary(line_length=150)\n",
    "# print(tf.shape(predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([  1 149 149  32], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "for test_index in range(10):\n",
    "    sample_img_batch, sample_cap_batch = next(iter(ds_val))\n",
    "    h = new_head_model(sample_img_batch)\n",
    "    s = new_tail_model(h)\n",
    "\n",
    "    # plt.imshow(tf.squeeze(sample_img_batch, [0]))\n",
    "\n",
    "    print(\"---\")\n",
    "    print(\"Reference  :\", end=' ')\n",
    "    n = sample_cap_batch.numpy()\n",
    "    index = 0\n",
    "    for x in n[0]:\n",
    "        if x > 0.1:\n",
    "            print(\"%s,\" % (classes[index]), end=' ')\n",
    "        index += 1\n",
    "    print(\"\")\n",
    "    print(\"Prediction :\", end=' ')\n",
    "    n = s.numpy()\n",
    "    index = 0\n",
    "    for x in n[0]:\n",
    "        if x > 0.5:\n",
    "            print(\"%s(%.2f),\" % (classes[index],x), end=' ')\n",
    "        index += 1\n",
    "    print(\"\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---\n",
      "Reference  : person, bus, book, \n",
      "Prediction : bus(0.99), \n",
      "---\n",
      "Reference  : person, bus, book, \n",
      "Prediction : bus(0.99), \n",
      "---\n",
      "Reference  : person, bus, book, \n",
      "Prediction : bus(0.99), \n",
      "---\n",
      "Reference  : person, bus, book, \n",
      "Prediction : bus(0.99), \n",
      "---\n",
      "Reference  : person, bus, book, \n",
      "Prediction : bus(0.99), \n",
      "---\n",
      "Reference  : person, car, traffic light, stop sign, \n",
      "Prediction : car(0.92), traffic light(0.67), \n",
      "---\n",
      "Reference  : bottle, cup, oven, sink, \n",
      "Prediction : oven(0.53), sink(0.63), \n",
      "---\n",
      "Reference  : remote, book, \n",
      "Prediction : bottle(0.54), \n",
      "---\n",
      "Reference  : person, car, handbag, \n",
      "Prediction : person(0.96), skateboard(0.89), \n",
      "---\n",
      "Reference  : person, tennis racket, \n",
      "Prediction : person(0.99), sports ball(0.52), tennis racket(1.00), \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "coco_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py373",
   "language": "python",
   "name": "py373"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}