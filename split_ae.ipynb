{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#!pip install --upgrade git+https://github.com/EmGarr/kerod.git"
   ],
   "outputs": [],
   "metadata": {
    "id": "1jVKNjhdLFUQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import  functools\n",
    "import  tensorflow as tf\n",
    "import  tensorflow_datasets as tfds\n",
    "from    tensorflow.keras.utils import to_categorical\n",
    "import  matplotlib.pyplot as plt\n",
    "from    tensorflow.keras import layers\n",
    "from    tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "import pandas as pd\n",
    "from    tqdm import tqdm\n",
    "import  time\n",
    "from    sklearn.metrics import accuracy_score\n",
    "import argparse\n",
    "\n",
    "from common.config import Config\n",
    "from common.logger import Logger\n",
    "from common.communication import Client\n",
    "from common.communication import Server\n",
    "from common.helper import ImagesInfo \n",
    "from common.timekeeper import TimeKeeper\n",
    "from common.helper import read_image, filt_text, get_predictions\n",
    "from CaptionModel import CaptionModel\n",
    "from common.helper import read_image, filt_text, get_predictions,process_predictions,get_reshape_size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-s', '--server', action='store', type=str, required=False)\n",
    "parser.add_argument('-t', '--test_number', action='store', type=int, required=False)\n",
    "parser.add_argument('-l', '--split_layer', action='store', type=int, required=False)\n",
    "parser.add_argument('-v', '--verbose', action='store', type=int, required=False)\n",
    "parser.add_argument('-i', '--image_size', action='store', type=int, required=False)\n",
    "parser.add_argument('-m', '--max_tests', action='store', type=int, required=False)\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "split_layer = args.split_layer\n",
    "\n",
    "if(split_layer == None):\n",
    "    split_layer = 3\n",
    "\n",
    "Logger.milestone_print(\"Splitting at layer %d\" % split_layer)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[92mSplitting at layer 3\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "tf.get_logger().setLevel('ERROR')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "N_LABELS = 80\n",
    "\n",
    "data_dir='/home/suphale/coco'\n",
    "split_train = \"train[:1%]\"\n",
    "split_val = \"validation[:1%]\"\n",
    "image_size = 250\n",
    "h_image_height = image_size\n",
    "h_image_width = image_size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "tk = TimeKeeper()\n",
    "cfg = Config()\n",
    "client = Client(cfg)\n",
    "imagesInfo = ImagesInfo(cfg)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from tensorflow import keras  # or import keras for standalone version\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "org_model = tf.keras.models.load_model(cfg.saved_model_path + '/iv3_full_model', compile=False)\n",
    "\n",
    "# basic_model = tf.keras.models.load_model(cfg.saved_model_path + '/model')\n",
    "# org_model = tf.keras.Model(inputs=basic_model.input, \n",
    "#         outputs=[basic_model.get_layer('mixed10').output, basic_model.get_layer('dense_1').output] )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model_config = org_model.get_config()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "max_layer_index = len(model_config['layers']) - 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "\n",
    "head_model_config = {}\n",
    "head_model_config['name'] = 'head_model'\n",
    "head_model_config['layers'] = []\n",
    "head_model_config['input_layers'] = [[model_config['layers'][0]['name'],0,0]]\n",
    "head_model_config['output_layers'] = [[model_config['layers'][split_layer+1-1]['name'],0,0]]\n",
    "\n",
    "for index in range(split_layer+1):\n",
    "    head_model_config['layers'].append(model_config['layers'][index])\n",
    "\n",
    "print(\"Final layer of head model [%d] %s\" % (split_layer, model_config['layers'][split_layer]['name']) )\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Final layer of head model [3] activation\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Last layer of the head model\n",
    "last_head_model_layer = head_model_config['layers'][split_layer]['name']\n",
    "# print(last_head_model_layer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# First layer of the tail model\n",
    "print(\"First layer of tail model [%d] %s\" % (split_layer+1, model_config['layers'][split_layer+1]['name']) )\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First layer of tail model [4] conv2d_1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import copy\n",
    "\n",
    "tail_model_config = copy.deepcopy(model_config)\n",
    "tail_model_config['name'] = 'tail_model'\n",
    "tail_model_config['input_layers'] = [[model_config['layers'][split_layer+1]['name'],0,0]]\n",
    "# tail_model_config['output_layers'] = [[model_config['layers'][max_layer_index]['name'],0,0]]\n",
    "tail_model_config['output_layers'] = model_config['output_layers']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# print(tail_model_config['input_layers'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# print(tail_model_config['output_layers'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "new_input_layer = {\n",
    "                      'name': 'new_input',\n",
    "                      'class_name': 'InputLayer',\n",
    "                      'config': {\n",
    "                          'batch_input_shape': tuple(org_model.layers[split_layer+1-1].output.shape),\n",
    "                          'dtype': 'float32',\n",
    "                          'sparse': False,\n",
    "                          'name': 'new_input'\n",
    "                      },\n",
    "                      'inbound_nodes': []\n",
    "                  }\n",
    "tail_model_config['layers'][0] = new_input_layer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "for index in range(1,split_layer+1):\n",
    "    # print(\"%d %s\" % (index, tail_model_config['layers'][1]['name']) )\n",
    "    tail_model_config['layers'].pop(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import numpy as np\n",
    "\n",
    "# Find if any layer in the tail model takes the last layer of head model as input\n",
    "# substitute it with the input layer\n",
    "# Ideally we should check if any tail model layer refers to any head model layer ToDo\n",
    "for index, layer in enumerate(tail_model_config['layers']):\n",
    "    if (np.shape(layer['inbound_nodes'])[0] > 0):\n",
    "        dim_1 = len(layer['inbound_nodes'][0])\n",
    "        if(dim_1 >= 1):\n",
    "            for i in range(dim_1):\n",
    "                in_layer = layer['inbound_nodes'][0][i][0]\n",
    "                if(in_layer == last_head_model_layer):\n",
    "                    print(str(index) + \"    \" + layer['name'] + \" -> \" + in_layer )\n",
    "                    # print(tail_model_config['layers'][index]['inbound_nodes'][0][i])\n",
    "                    tail_model_config['layers'][index]['inbound_nodes'][0][i] = [[['new_input', 0, 0, {}]]]\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1    conv2d_1 -> activation\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# tail_model_config['layers'][1]['inbound_nodes'] = [[['new_input', 0, 0, {}]]]\n",
    "tail_model_config['input_layers'] = [['new_input', 0, 0]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import pprint\n",
    "with open(cfg.temp_path + '/model_config.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    # fh.write(str(model_config))\n",
    "    print(model_config,file=fh)\n",
    "with open(cfg.temp_path + '/head_model_config.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    # fh.write(str(new_head_model_config))\n",
    "    print(head_model_config,file=fh)\n",
    "with open(cfg.temp_path + '/tail_model_config.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    # fh.write(str(new_head_model_config))\n",
    "    print(tail_model_config,file=fh)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "head_model = org_model.__class__.from_config(head_model_config, custom_objects={})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "tail_model = org_model.__class__.from_config(tail_model_config, custom_objects={})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "with open(cfg.temp_path + '/org_model.txt','w') as fh:\n",
    "    org_model.summary(print_fn=lambda x: fh.write(x + '\\n'), line_length=150)\n",
    "\n",
    "with open(cfg.temp_path + '/head_model.txt','w') as fh:\n",
    "    head_model.summary(print_fn=lambda x: fh.write(x + '\\n'), line_length=150)\n",
    "\n",
    "with open(cfg.temp_path + '/tail_model.txt','w') as fh:\n",
    "    tail_model.summary(print_fn=lambda x: fh.write(x + '\\n'), line_length=150)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "for index, layer in enumerate(org_model.layers[:split_layer+1]):\n",
    "    # print(\"[%d] %s %s\" % (index, layer.name, str(np.shape(weight))))\n",
    "    weight = layer.get_weights()\n",
    "    new_head_model_layer = head_model.layers[index]\n",
    "    new_head_model_layer.set_weights(weight)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "import numpy as np\n",
    "for index, layer in enumerate(org_model.layers[split_layer+1:max_layer_index+1]):\n",
    "    weight = layer.get_weights()\n",
    "    # print(\"org_model [%d] %s %s\" % (index, layer.name, str(tf.shape(weight))))\n",
    "    tail_model_layer = tail_model.layers[index+1]\n",
    "    tail_model_layer_weight = tail_model_layer.get_weights()\n",
    "    # print(\"tail_model [%d] %s %s\" % (index, tail_model_layer.name, str(tf.shape(tail_model_layer_weight))))\n",
    "    tail_model_layer.set_weights(weight)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "head_model.save(cfg.temp_path + '/iv3_head_model_'+str(split_layer))\n",
    "tail_model.save(cfg.temp_path + '/iv3_tail_model_'+str(split_layer))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "class BoxField:\n",
    "    BOXES = 'bbox'\n",
    "    KEYPOINTS = 'keypoints'\n",
    "    LABELS = 'label'\n",
    "    MASKS = 'masks'\n",
    "    NUM_BOXES = 'num_boxes'\n",
    "    SCORES = 'scores'\n",
    "    WEIGHTS = 'weights'\n",
    "\n",
    "class DatasetField:\n",
    "    IMAGES = 'images'\n",
    "    IMAGES_INFO = 'images_information'\n",
    "    IMAGES_PMASK = 'images_padding_mask'\n",
    "\n",
    "def my_preprocess(inputs):\n",
    "    image = inputs['image']\n",
    "    image = tf.image.resize(image, (h_image_height, h_image_width))\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 127.5\n",
    "    image -= 1.\n",
    "\n",
    "    targets = inputs['objects']\n",
    "\n",
    "    image_information = tf.cast(tf.shape(image)[:2], dtype=tf.float32)\n",
    "\n",
    "    inputs = {DatasetField.IMAGES: image, DatasetField.IMAGES_INFO: image_information}\n",
    "\n",
    "    # ground_truths = {\n",
    "    #     BoxField.BOXES: targets[BoxField.BOXES] * tf.tile(image_information[tf.newaxis], [1, 2]),\n",
    "    #     BoxField.LABELS: tf.cast(targets[BoxField.LABELS], tf.int32),\n",
    "    #     BoxField.NUM_BOXES: tf.shape(targets[BoxField.LABELS]),\n",
    "    #     BoxField.WEIGHTS: tf.fill(tf.shape(targets[BoxField.LABELS]), 1.0)\n",
    "    # }\n",
    "    ground_truths = tf.cast(targets[BoxField.LABELS], tf.int32)\n",
    "    ground_truths = tf.one_hot(ground_truths, depth=N_LABELS, dtype=tf.int32)\n",
    "    ground_truths = tf.reduce_sum(ground_truths, 0)\n",
    "    ground_truths = tf.greater( ground_truths, tf.constant( 0 ) )    \n",
    "    ground_truths = tf.where (ground_truths, 1, 0) \n",
    "    return image, ground_truths\n",
    "\n",
    "def expand_dims_for_single_batch(image, ground_truths):\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    ground_truths = tf.expand_dims(ground_truths, axis=0)\n",
    "    return image, ground_truths\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "ds_train, ds_info = tfds.load(name=\"coco/2017\", split=split_train, data_dir=data_dir, shuffle_files=True, download=False, with_info=True)\n",
    "ds_train = ds_train.map(functools.partial(my_preprocess), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.map(expand_dims_for_single_batch, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "ds_val, ds_info = tfds.load(name=\"coco/2017\", split=split_val, data_dir=data_dir, shuffle_files=False, download=False, with_info=True)\n",
    "ds_val = ds_val.map(functools.partial(my_preprocess), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_val = ds_val.map(expand_dims_for_single_batch, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_val = ds_val.prefetch(tf.data.experimental.AUTOTUNE)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: AutoGraph could not transform <function my_preprocess at 0x7f50329a8cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# org_model.save(cfg.temp_path + '/full_model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "classes = ds_info.features['objects']['label'].names\n",
    "num_classes = len(classes)\n",
    "print(num_classes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "80\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_writer = tf.io.TFRecordWriter('train.tfrecord')\n",
    "val_writer = tf.io.TFRecordWriter('val.tfrecord')\n",
    "\n",
    "sample_feature = None\n",
    "\n",
    "for test_index in tqdm(range(2)):\n",
    "    sample_img_batch, sample_cap_batch = next(iter(ds_train))\n",
    "    h = head_model(sample_img_batch)\n",
    "    features, result = tail_model(h)\n",
    "\n",
    "    n = h.numpy()\n",
    "    print(tf.shape(n))\n",
    "\n",
    "    # example = tf.train.Example(features = tf.train.Features(feature = {\n",
    "    #         'filename': tf.train.Feature(bytes_list = tf.train.BytesList(value = [bytes(filename, 'utf-8') ])),\n",
    "    #         'Image shapes': tf.train.Feature(int64_list = tf.train.Int64List(value = [img_shape[0],img_shape[1]])),\n",
    "    #         'image': tf.train.Feature(bytes_list = tf.train.BytesList(value = [image])),\n",
    "    #         'label': tf.train.Feature(bytes_list = tf.train.BytesList(value = [label]))}))\n",
    "\n",
    "    sample_feature={\n",
    "        'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[n.astype(np.int64).tobytes()])),\n",
    "        # 'label': tf.train.Feature(bytes_list=tf.train.BytesList(value=[sample_cap_batch])),\n",
    "    }\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=sample_feature))\n",
    "    train_writer.write(example.SerializeToString())\n",
    "\n",
    "    if(False):\n",
    "        print(\"Reference  : \", end=' ')\n",
    "        n = sample_cap_batch.numpy()\n",
    "        index = 0\n",
    "        for x in n[0]:\n",
    "            if x > 0.1:\n",
    "                print(\"%s,\" % (classes[index]), end=' ')\n",
    "            index += 1\n",
    "        print(\"\")\n",
    "        print(\"Prediction : \", end=' ')\n",
    "        n = result.numpy()\n",
    "        index = 0\n",
    "        for x in n[0]:\n",
    "            if x > 0.5:\n",
    "                print(\"%s(%.2f),\" % (classes[index],x), end=' ')\n",
    "            index += 1\n",
    "        print(\"\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.17it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([  1 124 124  32], shape=(4,), dtype=int32)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.05it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([  1 124 124  32], shape=(4,), dtype=int32)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "image_feature_description = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.int64),\n",
    "    # 'image': tf.train.Feature(bytes_list = tf.train.BytesList(value = [image]))\n",
    "    # 'label': tf.io.FixedLenFeature([], tf.int32),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    features = tf.io.parse_single_example(example_proto, sample_feature)\n",
    "    image = tf.io.decode_raw(features['image'], tf.int64)\n",
    "    # label = tf.io.decode_raw(features['image'], tf.uint8)\n",
    "\n",
    "    return image, image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "def read_dataset(epochs, batch_size, channel, channel_name):\n",
    "\n",
    "    filenames = [os.path.join(channel, channel_name + '.tfrecord')]\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "\n",
    "    dataset = dataset.map(_parse_image_function, num_parallel_calls=10)\n",
    "    dataset = dataset.prefetch(10)\n",
    "    dataset = dataset.repeat(epochs)\n",
    "    dataset = dataset.shuffle(buffer_size=10 * batch_size)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    return dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "train_dataset = read_dataset(1, 10, '.', 'train')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: AutoGraph could not transform <function _parse_image_function at 0x7f5033522d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "image_batch, label_batch = next(iter(train_dataset))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "DataLossError",
     "evalue": "truncated record at 194848929' failed with Read less bytes than requested",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/py373/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2112\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2114\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py373/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py373/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2579\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2580\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py373/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py373/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mDataLossError\u001b[0m: truncated record at 194848929' failed with Read less bytes than requested [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-246712bcf15a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py373/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py373/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py373/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py373/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2114\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2116\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py373/lib/python3.7/site-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataLossError\u001b[0m: truncated record at 194848929' failed with Read less bytes than requested"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "coco_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('py373': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "interpreter": {
   "hash": "53d8a323e6010706682c07af791323eacfc072764aa514c33420848fded080be"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}