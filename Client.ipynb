{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#!/usr/bin/env python3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import socket\n",
    "import os\n",
    "import json\n",
    "import  time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from   nltk.translate.bleu_score import sentence_bleu\n",
    "import random\n",
    "import  re\n",
    "import sys\n",
    "import argparse\n",
    "import zlib\n",
    "import pickle5 as pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Helper import Config, ImagesInfo, Logger, Client, TimeKeeper\n",
    "from Helper import read_image, filt_text, process_predictions\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-s', '--server', action='store', type=str, required=False)\n",
    "parser.add_argument('-t', '--test_number', action='store', type=int, required=False)\n",
    "parser.add_argument('-v', '--verbose', action='store', type=int, required=False)\n",
    "args, unknown = parser.parse_known_args()\n",
    "print(args.server)\n",
    "\n",
    "server_ip = args.server\n",
    "test_number = args.test_number\n",
    "verbose = args.verbose\n",
    "\n",
    "if(verbose == None):\n",
    "    verbose = 1\n",
    "\n",
    "if(test_number == None):\n",
    "    test_number = 4\n",
    "\n",
    "test_scenarios = {  1:\"Complete jpg file buffer transfer\", \n",
    "                    2:\"Decoded image buffer transfer\",\n",
    "                    3:\"Decoded image buffer transfer with zlib compression\",\n",
    "                    4:\"split model at layer 3\",\n",
    "                    5:\"split model at layer 3 with zlib compression\",\n",
    "                    }\n",
    "\n",
    "print(\"Test scenario = %d %s\" % (test_number, test_scenarios[test_number]))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Logger.set_log_level(verbose)\n",
    "tk = TimeKeeper()\n",
    "cfg = Config(server_ip)\n",
    "client = Client(cfg)\n",
    "imagesInfo = ImagesInfo(cfg)\n",
    "\n",
    "# client.connect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def evaluate_file_over_server(file_name):\n",
    "    with open(file_name, 'rb') as file_t:\n",
    "        byte_buffer_to_send = bytearray(file_t.read())\n",
    "        send_json_dict = {}\n",
    "        send_json_dict['data_type'] = 'file'\n",
    "        send_json_dict['file_name'] = file_name\n",
    "        send_json_dict['data_size'] = (len(byte_buffer_to_send))\n",
    "        send_json_dict['data_shape'] = \"(%d,)\" % (len(byte_buffer_to_send))\n",
    "        # send_json_dict['data_buffer'] = blob_data\n",
    "\n",
    "        app_json = json.dumps(send_json_dict)\n",
    "\n",
    "        tk.logInfo(img_path, tk.I_BUFFER_SIZE, len(byte_buffer_to_send))\n",
    "\n",
    "        tk.logTime(img_path, tk.E_START_COMMUNICATION)\n",
    "\n",
    "        response = client.send_data(str(app_json), byte_buffer_to_send)\n",
    "\n",
    "        tk.logTime(img_path, tk.E_STOP_COMMUNICATION)\n",
    "\n",
    "        response = json.loads(response)\n",
    "\n",
    "        predictions = response['predictions']\n",
    "        predictions_prob = response['predictions_prob']\n",
    "        # predictions = pickle.loads(predictions)\n",
    "        tail_model_time = response['tail_model_time']\n",
    "        tk.logInfo(img_path, tk.I_TAIL_MODEL_TIME, tail_model_time)\n",
    "\n",
    "        return predictions, predictions_prob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# tf.compat.v1.disable_eager_execution()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def evaluate_over_server(file_name, zlib_compression=False):\n",
    "    image_tensor = read_image(file_name)\n",
    "    image_tensor = tf.expand_dims(image_tensor, 0) \n",
    "\n",
    "    image_np_array = image_tensor.numpy()\n",
    "\n",
    "    byte_buffer_to_send = image_np_array.tobytes()\n",
    "    if(zlib_compression == True):\n",
    "        byte_buffer_to_send = zlib.compress(byte_buffer_to_send)\n",
    "\n",
    "    type(byte_buffer_to_send)\n",
    "\n",
    "    send_json_dict = {}\n",
    "    send_json_dict['data_type'] = 'data'\n",
    "    send_json_dict['file_name'] = file_name\n",
    "    send_json_dict['data_size'] = (len(byte_buffer_to_send))\n",
    "    send_json_dict['data_shape'] = image_np_array.shape\n",
    "    if(zlib_compression == True):\n",
    "        send_json_dict['zlib_compression'] = 'yes'\n",
    "    else:\n",
    "        send_json_dict['zlib_compression'] = 'no'\n",
    "\n",
    "    app_json = json.dumps(send_json_dict)\n",
    "\n",
    "    tk.logInfo(img_path, tk.I_BUFFER_SIZE, len(byte_buffer_to_send))\n",
    "\n",
    "    tk.logTime(img_path, tk.E_START_COMMUNICATION)\n",
    "\n",
    "    response = client.send_data(str(app_json), byte_buffer_to_send)\n",
    "\n",
    "    tk.logTime(img_path, tk.E_STOP_COMMUNICATION)\n",
    "\n",
    "    response = json.loads(response)\n",
    "\n",
    "    predictions = response['predictions']\n",
    "    predictions_prob = response['predictions_prob']\n",
    "    tail_model_time = response['tail_model_time']\n",
    "    tk.logInfo(img_path, tk.I_TAIL_MODEL_TIME, tail_model_time)\n",
    "\n",
    "    return predictions, predictions_prob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def evaluate_over_server_head_model(head_model, file_name, zlib_compression=False):\n",
    "\n",
    "    temp_input = tf.expand_dims(read_image(file_name), 0) \n",
    "    intermediate_tensor = head_model(temp_input)\n",
    "    image_np_array = intermediate_tensor.numpy()\n",
    "\n",
    "    byte_buffer_to_send = image_np_array.tobytes()\n",
    "    if(zlib_compression == True):\n",
    "        byte_buffer_to_send = zlib.compress(byte_buffer_to_send)\n",
    "\n",
    "    type(byte_buffer_to_send)\n",
    "\n",
    "    send_json_dict = {}\n",
    "    send_json_dict['data_type'] = 'data'\n",
    "    send_json_dict['file_name'] = file_name\n",
    "    send_json_dict['data_size'] = (len(byte_buffer_to_send))\n",
    "    send_json_dict['data_shape'] = image_np_array.shape\n",
    "    if(zlib_compression == True):\n",
    "        send_json_dict['zlib_compression'] = 'yes'\n",
    "    else:\n",
    "        send_json_dict['zlib_compression'] = 'no'\n",
    "\n",
    "    app_json = json.dumps(send_json_dict)\n",
    "\n",
    "    tk.logInfo(img_path, tk.I_BUFFER_SIZE, len(byte_buffer_to_send))\n",
    "\n",
    "    tk.logTime(img_path, tk.E_START_COMMUNICATION)\n",
    "\n",
    "    response = client.send_data(str(app_json), byte_buffer_to_send)\n",
    "\n",
    "    tk.logTime(img_path, tk.E_STOP_COMMUNICATION)\n",
    "\n",
    "    response = json.loads(response)\n",
    "\n",
    "    predictions = response['predictions']\n",
    "    predictions_prob = response['predictions_prob']\n",
    "    tail_model_time = response['tail_model_time']\n",
    "    tk.logInfo(img_path, tk.I_TAIL_MODEL_TIME, tail_model_time)\n",
    "\n",
    "    return predictions, predictions_prob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if(test_number in [1,2,3]):\n",
    "    # head_model = tf.keras.models.load_model(cfg.saved_model_path + '/model')\n",
    "    send_json_dict = {}\n",
    "    send_json_dict['data_type'] = 'load_model_request'\n",
    "    send_json_dict['model'] = '/model'\n",
    "    app_json = json.dumps(send_json_dict)\n",
    "    response = client.send_load_model_request(str(app_json))\n",
    "    assert(response == 'OK')\n",
    "if(test_number in [4,5]):\n",
    "    head_model = tf.keras.models.load_model(cfg.saved_model_path + '/new_head_model')\n",
    "    send_json_dict = {}\n",
    "    send_json_dict['data_type'] = 'load_model_request'\n",
    "    send_json_dict['model'] = '/new_tail_model'\n",
    "    app_json = json.dumps(send_json_dict)\n",
    "    response = client.send_load_model_request(str(app_json))\n",
    "    assert(response == 'OK')\n",
    "\n",
    "total_time = 0.0\n",
    "max_test_images = cfg.total_test_images\n",
    "df = pd.DataFrame(columns=['img_path','ground_truth', 'top_predict', 'Prediction', 'accuracy', 'top_1_accuracy', 'top_5_accuracy', 'precision', 'recall', 'time'])\n",
    "\n",
    "for i in tqdm(range(max_test_images)):\n",
    "    # Logger.event_print(\"\")\n",
    "    img_path = imagesInfo.getImagePath(i)\n",
    "    # image = io.imread(img_path)\n",
    "    # plt.imshow(image)\n",
    "    ground_truth = imagesInfo.get_segmentation_id_indexes(img_path)\n",
    "\n",
    "    tk.startRecord(img_path)\n",
    "    tk.logTime(img_path, tk.E_START_CLIENT_PROCESSING)\n",
    "\n",
    "    if(test_number == 1):\n",
    "        predictions,predictions_prob = evaluate_file_over_server(img_path)\n",
    "    if(test_number == 2):\n",
    "        predictions,predictions_prob = evaluate_over_server(img_path)\n",
    "    if(test_number == 3):\n",
    "        predictions,predictions_prob = evaluate_over_server(img_path,zlib_compression=True)\n",
    "    if(test_number == 4):\n",
    "        predictions,predictions_prob = evaluate_over_server_head_model(head_model, img_path)\n",
    "    if(test_number == 5):\n",
    "        predictions,predictions_prob = evaluate_over_server_head_model(head_model, img_path,zlib_compression=True)\n",
    "\n",
    "    tk.logTime(img_path, tk.E_STOP_CLIENT_PROCESSING)\n",
    "\n",
    "    accuracy, top_1_accuracy,top_5_accuracy,precision,recall, top_predictions, predictions_str = process_predictions(cfg, imagesInfo, ground_truth,predictions, predictions_prob)\n",
    "    df = df.append(\n",
    "        {'image':img_path, \n",
    "        'ground_truth':(str(imagesInfo.get_segmentation_texts(ground_truth))),\n",
    "        'top_predict':str(top_predictions),\n",
    "        'Prediction':predictions_str,\n",
    "        'accuracy':accuracy,\n",
    "        'top_1_accuracy':top_1_accuracy,\n",
    "        'top_5_accuracy':top_5_accuracy,\n",
    "        'precision':precision,\n",
    "        'recall':recall,\n",
    "        'time':0,\n",
    "        },\n",
    "        ignore_index = True)\n",
    "    truth_str = ' '.join([str(elem) for elem in imagesInfo.get_segmentation_texts(ground_truth)])\n",
    "    # Logger.debug_print(\"ground_truth  : %s\" % (truth_str))\n",
    "    # Logger.debug_print(\"Prediction    : %s\" % (predictions_str))\n",
    "\n",
    "    tk.finishRecord(img_path)\n",
    "\n",
    "df.to_csv(cfg.temp_path + '/results_'+cfg.timestr+'.csv')\n",
    "av_column = df.mean(axis=0)\n",
    "\n",
    "Logger.milestone_print(\"accuracy        : %.2f\" % (av_column.accuracy))\n",
    "Logger.milestone_print(\"top_1_accuracy  : %.2f\" % (av_column.top_1_accuracy))\n",
    "Logger.milestone_print(\"top_5_accuracy  : %.2f\" % (av_column.top_5_accuracy))\n",
    "Logger.milestone_print(\"precision       : %.2f\" % (av_column.precision))\n",
    "Logger.milestone_print(\"recall          : %.2f\" % (av_column.recall))\n",
    "Logger.milestone_print(\"time            : %.2f\" % (av_column.time))\n",
    "\n",
    "# tk.printAll()\n",
    "tk.summary()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53d8a323e6010706682c07af791323eacfc072764aa514c33420848fded080be"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('py373': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}