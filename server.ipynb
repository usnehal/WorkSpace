{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#!/usr/bin/env python3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from   tensorflow.keras import layers,Model\n",
    "import pickle5 as pickle\n",
    "from   tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from   tensorflow.keras.activations import tanh\n",
    "from   tensorflow.keras.activations import softmax\n",
    "from   numpy import float32\n",
    "from   numpy import byte\n",
    "import json\n",
    "import time\n",
    "import zlib\n",
    "import pickle5 as pickle\n",
    "\n",
    "from common.config import Config\n",
    "from common.logger import Logger\n",
    "from common.communication import Client\n",
    "from common.communication import Server\n",
    "from common.helper import ImagesInfo \n",
    "from common.timekeeper import TimeKeeper\n",
    "from common.helper import read_image, filt_text, get_predictions, get_reshape_size\n",
    "from CaptionModel import CaptionModel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class TailModel:\n",
    "    def __init__(self,cfg):\n",
    "        self.cfg = cfg\n",
    "        self.model = None\n",
    "\n",
    "    def evaluate(self,image):\n",
    "        result = self.model(image)\n",
    "        return result\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model = None\n",
    "captionModel = None\n",
    "\n",
    "def handle_load_model(msg,model_path_requested):\n",
    "    global model\n",
    "    global captionModel\n",
    "    if(msg == 'model'):\n",
    "        model_path = cfg.saved_model_path + model_path_requested\n",
    "        Logger.milestone_print(\"Loading model : from %s\" % (model_path))\n",
    "        model = None\n",
    "        model = tf.keras.models.load_model(model_path, compile=False)\n",
    "        # model = tf.keras.models.load_model(cfg.temp_path + '/extractor_model', compile=False)\n",
    "        return \"OK\"\n",
    "    if(msg == 'captionModel'):\n",
    "        model_path = cfg.saved_model_path + model_path_requested\n",
    "        captionModel = None\n",
    "        Logger.milestone_print(\"Loading caption model : from %s\" % (model_path))\n",
    "        captionModel = CaptionModel(model_path=model_path)\n",
    "        return \"OK\"\n",
    "    if(msg == 'tail_model'):\n",
    "        model_path = cfg.saved_model_path + \"/\" + model_path_requested\n",
    "        Logger.milestone_print(\"Loading model : from %s\" % (model_path))\n",
    "        model = None\n",
    "        model = tf.keras.models.load_model(model_path, compile=False)\n",
    "        return \"OK\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def handle_image_file(msg,shape,image_size):\n",
    "    temp_file = '/tmp/temp.bin'\n",
    "    f = open(temp_file, \"wb\")\n",
    "    f.write(msg)\n",
    "    f.close()\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    image_tensor = tf.expand_dims(read_image(temp_file), 0) \n",
    "    features, result = model(image_tensor)\n",
    "    features = tf.reshape(features, [1,get_reshape_size(image_size)*get_reshape_size(image_size), 2048])\n",
    "    caption_tensor = captionModel.evaluate(features)\n",
    "    t1 = time.perf_counter() - t0\n",
    "\n",
    "    top_predictions, predictions_prob = get_predictions(cfg, result)\n",
    "\n",
    "    send_json_dict = {}\n",
    "    send_json_dict['response'] = 'OK'\n",
    "    send_json_dict['predictions'] = top_predictions\n",
    "    send_json_dict['predictions_prob'] = predictions_prob\n",
    "    send_json_dict['predicted_captions'] = caption_tensor\n",
    "    send_json_dict['tail_model_time'] = t1\n",
    "\n",
    "    app_json = json.dumps(send_json_dict)\n",
    "\n",
    "    return str(app_json)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def handle_image_tensor(msg,shape,image_size):\n",
    "    generated_np_array = np.frombuffer(msg, dtype=float32)\n",
    "    generated_np_array = np.frombuffer(generated_np_array, dtype=float32)\n",
    "    generated_image_np_array = generated_np_array.reshape(shape)\n",
    "    image_tensor = tf.convert_to_tensor(generated_image_np_array, dtype=tf.float32)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    features, result = model(image_tensor)\n",
    "    features = tf.reshape(features, [1,get_reshape_size(image_size)*get_reshape_size(image_size), 2048])\n",
    "    caption_tensor = captionModel.evaluate(features)\n",
    "    t1 = time.perf_counter() - t0\n",
    "\n",
    "    top_predictions, predictions_prob = get_predictions(cfg, result)\n",
    "\n",
    "    send_json_dict = {}\n",
    "    send_json_dict['response'] = 'OK'\n",
    "    send_json_dict['predictions'] = top_predictions\n",
    "    send_json_dict['predictions_prob'] = predictions_prob\n",
    "    send_json_dict['predicted_captions'] = caption_tensor\n",
    "    send_json_dict['tail_model_time'] = t1\n",
    "\n",
    "    app_json = json.dumps(send_json_dict)\n",
    "\n",
    "    return str(app_json)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "Logger.set_log_level(1)\n",
    "# logger = Logger()\n",
    "tk = TimeKeeper()\n",
    "cfg = Config(None)\n",
    "client = Client(cfg)\n",
    "imagesInfo = ImagesInfo(cfg)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "tailModel = TailModel(cfg)\n",
    "server = Server(cfg)\n",
    "server.register_callback('data',handle_image_tensor)\n",
    "server.register_callback('file',handle_image_file)\n",
    "server.register_callback('load_model_request',handle_load_model)\n",
    "server.accept_connections()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[92mRunning on IP: \u001b[0m\n",
      "\u001b[92mRunning on port: 5002\u001b[0m\n",
      "\u001b[92mLoading model : from /home/suphale/WorkSpace/saved_model//iv3_head_model_3\u001b[0m\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "\u001b[92mLoading caption model : from /home/suphale/WorkSpace/saved_model/caption_i_400\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/suphale/anaconda3/envs/py373/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/suphale/anaconda3/envs/py373/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/suphale/WorkSpace/common/communication.py\", line 166, in handle_client\n",
      "    response = callback(msg,tensor_shape,image_size)\n",
      "  File \"<ipython-input-6-a6c100cc826b>\", line 8, in handle_image_tensor\n",
      "    features, result = model(image_tensor)\n",
      "  File \"/home/suphale/anaconda3/envs/py373/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 998, in __call__\n",
      "    input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n",
      "  File \"/home/suphale/anaconda3/envs/py373/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py\", line 274, in assert_input_compatibility\n",
      "    ', found shape=' + display_shape(x.shape))\n",
      "ValueError: Input 0 is incompatible with layer head_model: expected shape=(None, None, None, 3), found shape=(1, 199, 199, 32)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[92mLoading model : from /home/suphale/WorkSpace/saved_model//iv3_tail_model_3\u001b[0m\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "\u001b[92mLoading caption model : from /home/suphale/WorkSpace/saved_model/caption_i_400\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53d8a323e6010706682c07af791323eacfc072764aa514c33420848fded080be"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('py373': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}