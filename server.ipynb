{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#!/usr/bin/env python3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from   tensorflow.keras import layers,Model\n",
    "import pickle5 as pickle\n",
    "from   tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from   tensorflow.keras.activations import tanh\n",
    "from   tensorflow.keras.activations import softmax\n",
    "from   numpy import float32\n",
    "from   numpy import byte\n",
    "import json\n",
    "import time\n",
    "import zlib\n",
    "import pickle5 as pickle\n",
    "\n",
    "from common.config import Config\n",
    "from common.logger import Logger\n",
    "from common.communication import Client\n",
    "from common.communication import Server\n",
    "from common.helper import ImagesInfo \n",
    "from common.timekeeper import TimeKeeper\n",
    "from common.helper import read_image, filt_text, get_predictions\n",
    "from CaptionModel import CaptionModel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class TailModel:\n",
    "    def __init__(self,cfg):\n",
    "        self.cfg = cfg\n",
    "        self.model = None\n",
    "\n",
    "    def evaluate(self,image):\n",
    "        result = self.model(image)\n",
    "        return result\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model = None\n",
    "captionModel = None\n",
    "\n",
    "def handle_load_model(msg,shape):\n",
    "    global model\n",
    "    global captionModel\n",
    "    if(msg == 'model'):\n",
    "        model_path = cfg.saved_model_path + '/model'\n",
    "        Logger.milestone_print(\"Loading model : %s from %s\" % (model,model_path))\n",
    "        model = None\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        # model = tf.keras.models.load_model(cfg.temp_path + '/extractor_model')\n",
    "        return \"OK\"\n",
    "    if(msg == 'captionModel'):\n",
    "        Logger.milestone_print(\"Loading model : %s\" % (msg))\n",
    "        captionModel = None\n",
    "        captionModel = CaptionModel()\n",
    "        return \"OK\"\n",
    "    if(msg == 'tail_model'):\n",
    "        model_path = cfg.saved_model_path + '/tail_model'\n",
    "        Logger.milestone_print(\"Loading model : %s from %s\" % (model,model_path))\n",
    "        model = None\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        return \"OK\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def handle_image_file(msg,shape):\n",
    "    temp_file = '/tmp/temp.bin'\n",
    "    f = open(temp_file, \"wb\")\n",
    "    f.write(msg)\n",
    "    f.close()\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    image_tensor = tf.expand_dims(read_image(temp_file), 0) \n",
    "    features, result = model(image_tensor)\n",
    "    features = tf.reshape(features, [1,8*8, 2048])\n",
    "    caption_tensor = captionModel.evaluate(features)\n",
    "    t1 = time.perf_counter() - t0\n",
    "\n",
    "    top_predictions, predictions_prob = get_predictions(cfg, result)\n",
    "\n",
    "    send_json_dict = {}\n",
    "    send_json_dict['response'] = 'OK'\n",
    "    send_json_dict['predictions'] = top_predictions\n",
    "    send_json_dict['predictions_prob'] = predictions_prob\n",
    "    send_json_dict['predicted_captions'] = caption_tensor\n",
    "    send_json_dict['tail_model_time'] = t1\n",
    "\n",
    "    app_json = json.dumps(send_json_dict)\n",
    "\n",
    "    return str(app_json)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def handle_image_tensor(msg,shape):\n",
    "    generated_np_array = np.frombuffer(msg, dtype=float32)\n",
    "    generated_np_array = np.frombuffer(generated_np_array, dtype=float32)\n",
    "    generated_image_np_array = generated_np_array.reshape(shape)\n",
    "    image_tensor = tf.convert_to_tensor(generated_image_np_array, dtype=tf.float32)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    features, result = model(image_tensor)\n",
    "    features = tf.reshape(features, [1,8*8, 2048])\n",
    "    caption_tensor = captionModel.evaluate(features)\n",
    "    t1 = time.perf_counter() - t0\n",
    "\n",
    "    top_predictions, predictions_prob = get_predictions(cfg, result)\n",
    "\n",
    "    send_json_dict = {}\n",
    "    send_json_dict['response'] = 'OK'\n",
    "    send_json_dict['predictions'] = top_predictions\n",
    "    send_json_dict['predictions_prob'] = predictions_prob\n",
    "    send_json_dict['predicted_captions'] = caption_tensor\n",
    "    send_json_dict['tail_model_time'] = t1\n",
    "\n",
    "    app_json = json.dumps(send_json_dict)\n",
    "\n",
    "    return str(app_json)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def extract_image_features(self, sample_img_batch):\n",
    "    features = self.image_features_extract_model(sample_img_batch)\n",
    "    features = tf.reshape(features, [sample_img_batch.shape[0],8*8, 2048])\n",
    "    return features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "Logger.set_log_level(1)\n",
    "# logger = Logger()\n",
    "tk = TimeKeeper()\n",
    "cfg = Config(None)\n",
    "client = Client(cfg)\n",
    "imagesInfo = ImagesInfo(cfg)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "tailModel = TailModel(cfg)\n",
    "server = Server(cfg)\n",
    "server.register_callback('data',handle_image_tensor)\n",
    "server.register_callback('file',handle_image_file)\n",
    "server.register_callback('load_model_request',handle_load_model)\n",
    "server.accept_connections()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[92mRunning on IP: \u001b[0m\n",
      "\u001b[92mRunning on port: 5001\u001b[0m\n",
      "\u001b[92mLoading model : None from /home/suphale/WorkSpace/saved_model/model\u001b[0m\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "\u001b[92mLoading model : captionModel\u001b[0m\n",
      "\u001b[92mLoading model : <tensorflow.python.keras.engine.functional.Functional object at 0x7fba893995d0> from /home/suphale/WorkSpace/saved_model/tail_model\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Exception in thread Thread-56:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/suphale/anaconda3/envs/py373/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/suphale/anaconda3/envs/py373/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/suphale/WorkSpace/common/communication.py\", line 123, in handle_client\n",
      "    response = callback(model_type,None)\n",
      "  File \"<ipython-input-4-8f7534b3ca87>\", line 23, in handle_load_model\n",
      "    model = tf.keras.models.load_model(cfg.saved_model_path + msg)\n",
      "  File \"/home/suphale/anaconda3/envs/py373/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\", line 211, in load_model\n",
      "    loader_impl.parse_saved_model(filepath)\n",
      "  File \"/home/suphale/anaconda3/envs/py373/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 114, in parse_saved_model\n",
      "    constants.SAVED_MODEL_FILENAME_PB))\n",
      "OSError: SavedModel file does not exist at: /home/suphale/WorkSpace/saved_modeltail_model/{saved_model.pbtxt|saved_model.pb}\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53d8a323e6010706682c07af791323eacfc072764aa514c33420848fded080be"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('py373': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}