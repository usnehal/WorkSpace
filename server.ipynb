{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#!/usr/bin/env python3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from   tensorflow.keras import layers,Model\n",
    "import pickle5 as pickle\n",
    "from   tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from   tensorflow.keras.activations import tanh\n",
    "from   tensorflow.keras.activations import softmax\n",
    "from   numpy import float32\n",
    "from   numpy import byte\n",
    "import json\n",
    "import time\n",
    "import zlib\n",
    "import pickle5 as pickle\n",
    "\n",
    "from common.config import Config\n",
    "from common.logger import Logger\n",
    "from common.communication import Client\n",
    "from common.communication import Server\n",
    "from common.helper import ImagesInfo \n",
    "from common.timekeeper import TimeKeeper\n",
    "from common.helper import read_image, filt_text, get_predictions\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In WSL\n",
      "In WSL\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class TailModel:\n",
    "    def __init__(self,cfg):\n",
    "        self.cfg = cfg\n",
    "        self.model = None\n",
    "\n",
    "    def evaluate(self,image):\n",
    "        result = self.model(image)\n",
    "        return result\n",
    "\n",
    "    def handle_load_model(self,msg,shape):\n",
    "        Logger.milestone_print(\"Loading model : %s\" % (cfg.saved_model_path + msg))\n",
    "        self.model = None\n",
    "        self.model = tf.keras.models.load_model(cfg.saved_model_path + msg)\n",
    "        return \"OK\"\n",
    "\n",
    "    def handle_image_file(self,msg,shape):\n",
    "        temp_file = '/tmp/temp.bin'\n",
    "        f = open(temp_file, \"wb\")\n",
    "        f.write(msg)\n",
    "        f.close()\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        image_tensor = tf.expand_dims(read_image(temp_file), 0) \n",
    "        result = self.evaluate(image_tensor)\n",
    "        t1 = time.perf_counter() - t0\n",
    "\n",
    "        top_predictions, predictions_prob = get_predictions(cfg, result)\n",
    "\n",
    "        send_json_dict = {}\n",
    "        send_json_dict['response'] = 'OK'\n",
    "        send_json_dict['predictions'] = top_predictions\n",
    "        send_json_dict['predictions_prob'] = predictions_prob\n",
    "        send_json_dict['tail_model_time'] = t1\n",
    "\n",
    "        app_json = json.dumps(send_json_dict)\n",
    "\n",
    "        return str(app_json)\n",
    "\n",
    "    def handle_image_tensor(self,msg,shape):\n",
    "        generated_np_array = np.frombuffer(msg, dtype=float32)\n",
    "        generated_np_array = np.frombuffer(generated_np_array, dtype=float32)\n",
    "        generated_image_np_array = generated_np_array.reshape(shape)\n",
    "        image_tensor = tf.convert_to_tensor(generated_image_np_array, dtype=tf.float32)\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        result  = self.evaluate(image_tensor)\n",
    "        t1 = time.perf_counter() - t0\n",
    "\n",
    "        top_predictions, predictions_prob = get_predictions(cfg, result)\n",
    "\n",
    "        send_json_dict = {}\n",
    "        send_json_dict['response'] = 'OK'\n",
    "        send_json_dict['predictions'] = top_predictions\n",
    "        send_json_dict['predictions_prob'] = predictions_prob\n",
    "        send_json_dict['tail_model_time'] = t1\n",
    "\n",
    "        app_json = json.dumps(send_json_dict)\n",
    "\n",
    "        return str(app_json)\n",
    "        \n",
    "    def extract_image_features(self, sample_img_batch):\n",
    "        features = self.image_features_extract_model(sample_img_batch)\n",
    "        features = tf.reshape(features, [sample_img_batch.shape[0],8*8, 2048])\n",
    "        return features\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "Logger.set_log_level(1)\n",
    "# logger = Logger()\n",
    "tk = TimeKeeper()\n",
    "cfg = Config(None)\n",
    "client = Client(cfg)\n",
    "imagesInfo = ImagesInfo(cfg)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In WSL\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "cfg = Config(None)\n",
    "tailModel = TailModel(cfg)\n",
    "server = Server(cfg, tailModel)\n",
    "server.register_callback('data',tailModel.handle_image_tensor)\n",
    "server.register_callback('file',tailModel.handle_image_file)\n",
    "server.register_callback('load_model_request',tailModel.handle_load_model)\n",
    "server.accept_connections()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In WSL\n",
      "register_callback obj=data\n",
      "register_callback self.callbacks={'data': <bound method TailModel.handle_image_tensor of <__main__.TailModel object at 0x7fb587e31c90>>}\n",
      "register_callback obj=file\n",
      "register_callback self.callbacks={'data': <bound method TailModel.handle_image_tensor of <__main__.TailModel object at 0x7fb587e31c90>>, 'file': <bound method TailModel.handle_image_file of <__main__.TailModel object at 0x7fb587e31c90>>}\n",
      "register_callback obj=load_model_request\n",
      "register_callback self.callbacks={'data': <bound method TailModel.handle_image_tensor of <__main__.TailModel object at 0x7fb587e31c90>>, 'file': <bound method TailModel.handle_image_file of <__main__.TailModel object at 0x7fb587e31c90>>, 'load_model_request': <bound method TailModel.handle_load_model of <__main__.TailModel object at 0x7fb587e31c90>>}\n",
      "\u001b[92mRunning on IP: \u001b[0m\n",
      "\u001b[92mRunning on port: 5002\u001b[0m\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'threading' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6d0fc5b1e1cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtailModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_image_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_model_request'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtailModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_load_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccept_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/WorkSpace/common/communication.py\u001b[0m in \u001b[0;36maccept_connections\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# print(c)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maddr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maddr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'threading' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53d8a323e6010706682c07af791323eacfc072764aa514c33420848fded080be"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('py373': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}