{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#!pip install --upgrade git+https://github.com/EmGarr/kerod.git"
   ],
   "outputs": [],
   "metadata": {
    "id": "1jVKNjhdLFUQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print('GPU device not found')\n",
    "else:\n",
    "    print('Found GPU at: {}'.format(device_name))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU device not found\n"
     ]
    }
   ],
   "metadata": {
    "id": "CET-72i5EmKn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import  functools\n",
    "import  tensorflow as tf\n",
    "import  tensorflow_datasets as tfds\n",
    "from    tensorflow.keras.utils import to_categorical\n",
    "import  matplotlib.pyplot as plt\n",
    "from    tensorflow.keras import layers\n",
    "from    tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "import pandas as pd\n",
    "from    tqdm import tqdm\n",
    "import  time\n",
    "from    sklearn.metrics import accuracy_score\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from Helper import Config, ImagesInfo, Logger, Client, TimeKeeper\n",
    "from Helper import read_image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "data_dir='/home/suphale/coco'\n",
    "N_LABELS = 80\n",
    "N_EPOCHS = 1\n",
    "TRAIN_MODE = False\n",
    "split_train = \"train[:1%]\"\n",
    "split_val = \"validation[:1%]\"\n",
    "h_image_height = 299\n",
    "h_image_width = 299\n",
    "\n",
    "SPLIT_LAYER = 4\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "tk = TimeKeeper()\n",
    "cfg = Config()\n",
    "client = Client(cfg)\n",
    "imagesInfo = ImagesInfo(cfg)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In WSL\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load and train the network\n"
   ],
   "metadata": {
    "id": "9tt34CM6P-gr"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from tensorflow import keras  # or import keras for standalone version\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "# org_model = tf.keras.models.load_model(cfg.temp_path + '/model')\n",
    "org_model = tf.keras.models.load_model(cfg.temp_path + '/model_2021_07_21')\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model_config = org_model.get_config()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "max_layer_index = len(model_config['layers']) - 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "\n",
    "new_head_model_config = {}\n",
    "new_head_model_config['name'] = 'head_model'\n",
    "new_head_model_config['layers'] = []\n",
    "new_head_model_config['input_layers'] = [[model_config['layers'][0]['name'],0,0]]\n",
    "new_head_model_config['output_layers'] = [[model_config['layers'][SPLIT_LAYER-1]['name'],0,0]]\n",
    "\n",
    "for index in range(SPLIT_LAYER):\n",
    "    print(\"%d %s\" % (index, model_config['layers'][index]['name']) )\n",
    "    new_head_model_config['layers'].append(model_config['layers'][index])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 input_1\n",
      "1 conv2d\n",
      "2 batch_normalization\n",
      "3 activation\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import copy\n",
    "\n",
    "new_tail_model_config = copy.deepcopy(model_config)\n",
    "new_tail_model_config['name'] = 'tail_model'\n",
    "new_tail_model_config['input_layers'] = [[model_config['layers'][SPLIT_LAYER]['name'],0,0]]\n",
    "new_tail_model_config['output_layers'] = [[model_config['layers'][max_layer_index]['name'],0,0]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# tuple(org_model.layers[0].output.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "new_input_layer = {\n",
    "                      'name': 'new_input',\n",
    "                      'class_name': 'InputLayer',\n",
    "                      'config': {\n",
    "                          'batch_input_shape': tuple(org_model.layers[SPLIT_LAYER].output.shape),\n",
    "                          'dtype': 'float32',\n",
    "                          'sparse': False,\n",
    "                          'name': 'new_input'\n",
    "                      },\n",
    "                      'inbound_nodes': []\n",
    "                  }\n",
    "new_tail_model_config['layers'][0] = new_input_layer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "for index in range(1,SPLIT_LAYER):\n",
    "    print(\"%d %s\" % (index, new_tail_model_config['layers'][1]['name']) )\n",
    "    # new_tail_model_config['layers'].append(model_config['layers'][index])\n",
    "    new_tail_model_config['layers'].pop(1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 conv2d\n",
      "2 batch_normalization\n",
      "3 activation\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# input_layer_name = model_config['layers'][0]['name']\n",
    "new_tail_model_config['layers'][1]['inbound_nodes'] = [[['new_input', 0, 0, {}]]]\n",
    "new_tail_model_config['input_layers'] = [['new_input', 0, 0]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import pprint\n",
    "with open(cfg.temp_path + '/model_config.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    # fh.write(str(model_config))\n",
    "    pp = pprint.PrettyPrinter(indent=4, stream=fh)\n",
    "    pp.pprint(str(model_config))\n",
    "with open(cfg.temp_path + '/new_head_model_config.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    # fh.write(str(new_head_model_config))\n",
    "    pp = pprint.PrettyPrinter(indent=4, stream=fh)\n",
    "    pp.pprint(str(new_head_model_config))\n",
    "with open(cfg.temp_path + '/new_tail_model_config.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    # fh.write(str(new_head_model_config))\n",
    "    pp = pprint.PrettyPrinter(indent=4, stream=fh)\n",
    "    pp.pprint(str(new_tail_model_config))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "new_head_model = org_model.__class__.from_config(new_head_model_config, custom_objects={})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "new_tail_model = org_model.__class__.from_config(new_tail_model_config, custom_objects={})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "with open(cfg.temp_path + '/org_model.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    org_model.summary(print_fn=lambda x: fh.write(x + '\\n'), line_length=150)\n",
    "\n",
    "with open(cfg.temp_path + '/new_head_model.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    new_head_model.summary(print_fn=lambda x: fh.write(x + '\\n'), line_length=150)\n",
    "\n",
    "with open(cfg.temp_path + '/new_tail_model.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    new_tail_model.summary(print_fn=lambda x: fh.write(x + '\\n'), line_length=150)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "for index, layer in enumerate(org_model.layers[:SPLIT_LAYER]):\n",
    "    # print(\"[%d] %s %s\" % (index, layer.name, str(np.shape(weight))))\n",
    "    weight = layer.get_weights()\n",
    "    new_head_model_layer = new_head_model.layers[index]\n",
    "    new_head_model_layer.set_weights(weight)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "for index, layer in enumerate(org_model.layers[SPLIT_LAYER:max_layer_index+1]):\n",
    "    weight = layer.get_weights()\n",
    "    # print(\"[%d] %s %s\" % (index, layer.name, str(np.shape(weight))))\n",
    "    new_tail_model_layer = new_tail_model.layers[index+1]\n",
    "    # print(\"[%d] %s %s\" % (index, new_tail_model_layer.name, str(np.shape(weight))))\n",
    "    new_tail_model_layer.set_weights(weight)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "new_head_model.save(cfg.temp_path + '/new_head_model')\n",
    "new_tail_model.save(cfg.temp_path + '/new_tail_model')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: ./temp/new_head_model/assets\n",
      "INFO:tensorflow:Assets written to: ./temp/new_tail_model/assets\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def process_predictions(ground_truth, prediction_tensor):\n",
    "    n = tf.squeeze(prediction_tensor).numpy()\n",
    "    df = pd.DataFrame(columns=['id_index','probability'])\n",
    "    predictions_str = ''\n",
    "    top_predictions = []\n",
    "    index = 0\n",
    "    for x in n:\n",
    "        if x > cfg.PREDICTIONS_THRESHOLD:\n",
    "            top_predictions.append(index)\n",
    "            predictions_str += \"%s(%.2f) \" % (imagesInfo.classes[index],x)\n",
    "            df = df.append({'id_index':int(index), 'probability':x},ignore_index = True)\n",
    "        index += 1\n",
    "\n",
    "    df = df.sort_values('probability', ascending=False)\n",
    "    sorted_predictions = df['id_index'].tolist()\n",
    "    sorted_predictions = [int(x) for x in sorted_predictions]\n",
    "\n",
    "    ground_truth_length = len(ground_truth)\n",
    "    predictions_length = len(sorted_predictions)\n",
    "\n",
    "    aligned_predictions = [-1] * ground_truth_length\n",
    "    TP = 0\n",
    "    for i in range(ground_truth_length):\n",
    "        if(ground_truth[i] in sorted_predictions):\n",
    "            aligned_predictions[i] = ground_truth[i]\n",
    "            TP += 1\n",
    "    accuracy = accuracy_score(ground_truth, aligned_predictions)\n",
    "\n",
    "    top_1_accuracy = 0.0\n",
    "    top_5_accuracy = 0.0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    if(predictions_length > 0):\n",
    "        if(sorted_predictions[0] in ground_truth):\n",
    "            top_1_accuracy = 1.0\n",
    "        for i in range(5):\n",
    "            if((i < predictions_length) and (sorted_predictions[i] in ground_truth)):\n",
    "                top_5_accuracy = 1.0\n",
    "\n",
    "        precision = TP / predictions_length\n",
    "    recall = TP / ground_truth_length\n",
    "    return accuracy, top_1_accuracy,top_5_accuracy,precision,recall, top_predictions, predictions_str\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def evaluate_classification(image):\n",
    "    temp_input = tf.expand_dims(read_image(image), 0) \n",
    "    h = new_head_model(temp_input)\n",
    "    s = new_tail_model(h)\n",
    "    return s"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "total_test_images= 100\n",
    "total_time = 0.0\n",
    "max_test_images = total_test_images\n",
    "df = pd.DataFrame(columns=['img_path','ground_truth', 'top_predict', 'Prediction', 'accuracy', 'top_1_accuracy', 'top_5_accuracy', 'precision', 'recall', 'time'])\n",
    "\n",
    "for i in tqdm(range(max_test_images)):\n",
    "    Logger.debug_print(\"\")\n",
    "    img_path = imagesInfo.all_img_vector[i]\n",
    "    # plt.imshow(image)\n",
    "    ground_truth = imagesInfo.get_segmentation_id_indexes(img_path)\n",
    "\n",
    "    test_image = img_path\n",
    "\n",
    "    t0= time.perf_counter()\n",
    "    s = evaluate_classification(test_image)\n",
    "    t1 = time.perf_counter() - t0\n",
    "    total_time = total_time + t1\n",
    "\n",
    "    accuracy, top_1_accuracy,top_5_accuracy,precision,recall, top_predictions, predictions_str = process_predictions(ground_truth,s)\n",
    "    df = df.append(\n",
    "        {'image':img_path, \n",
    "        'ground_truth':(str(imagesInfo.get_segmentation_texts(ground_truth))),\n",
    "        'top_predict':str(top_predictions),\n",
    "        'Prediction':predictions_str,\n",
    "        'accuracy':accuracy,\n",
    "        'top_1_accuracy':top_1_accuracy,\n",
    "        'top_5_accuracy':top_5_accuracy,\n",
    "        'precision':precision,\n",
    "        'recall':recall,\n",
    "        'time':t1,\n",
    "        },\n",
    "        ignore_index = True)\n",
    "    truth_str = ' '.join([str(elem) for elem in imagesInfo.get_segmentation_texts(ground_truth)])\n",
    "    Logger.debug_print(\"ground_truth  : %s\" % (truth_str))\n",
    "    Logger.debug_print(\"Prediction    : %s\" % (predictions_str))\n",
    "\n",
    "df.to_csv(cfg.temp_path + '/results_'+cfg.timestr+'.csv')\n",
    "av_column = df.mean(axis=0)\n",
    "\n",
    "Logger.milestone_print(\"accuracy        : %.2f\" % (av_column.accuracy))\n",
    "Logger.milestone_print(\"top_1_accuracy  : %.2f\" % (av_column.top_1_accuracy))\n",
    "Logger.milestone_print(\"top_5_accuracy  : %.2f\" % (av_column.top_5_accuracy))\n",
    "Logger.milestone_print(\"precision       : %.2f\" % (av_column.precision))\n",
    "Logger.milestone_print(\"recall          : %.2f\" % (av_column.recall))\n",
    "Logger.milestone_print(\"time            : %.2f\" % (av_column.time))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 100/100 [00:54<00:00,  1.82it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[92maccuracy        : 0.53\u001b[0m\n",
      "\u001b[92mtop_1_accuracy  : 0.70\u001b[0m\n",
      "\u001b[92mtop_5_accuracy  : 0.90\u001b[0m\n",
      "\u001b[92mprecision       : 0.68\u001b[0m\n",
      "\u001b[92mrecall          : 0.53\u001b[0m\n",
      "\u001b[92mtime            : 0.52\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "coco_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py373",
   "language": "python",
   "name": "py373"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}